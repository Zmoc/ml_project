{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32ea8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# URL: https://csr.lanl.gov/data/cyber1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c208d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_auth_path = \"raw_data/auth.txt\"\n",
    "src_dns_path = \"raw_data/dns.txt\"\n",
    "src_flows_path = \"raw_data/flows.txt\"\n",
    "src_proc_path = \"raw_data/proc.txt\"\n",
    "src_redteam_path = \"raw_data/redteam.txt\"\n",
    "\n",
    "dst_auth_path = \"processed_data/cleaned/auth.csv\"\n",
    "dst_dns_path = \"processed_data/cleaned/dns.csv\"\n",
    "dst_flows_path = \"processed_data/cleaned/flows.csv\"\n",
    "dst_proc_path = \"processed_data/cleaned/proc.csv\"\n",
    "dst_redteam_path = \"processed_data/cleaned/redteam.csv\"\n",
    "\n",
    "train_final_path = \"processed_data/cleaned/training_final.csv\"\n",
    "test_final_path = \"processed_data/cleaned/testing_final.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd12f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 1 # 1 second\n",
    "day_seconds = 1*24*60*60\n",
    "train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20a28ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150885\n"
     ]
    }
   ],
   "source": [
    "redteam_headers = [\"time\",\n",
    "                   \"user@domain\",\n",
    "                   \"src_comp\",\n",
    "                   \"dst_comp\"]\n",
    "redteam_df = pd.read_csv(src_redteam_path, header=None,names=redteam_headers)\n",
    "redteam_df[['src_user', 'src_domain']] = redteam_df[\"user@domain\"].str.split(\"@\", expand=True)\n",
    "redteam_df.drop(columns=['user@domain'],inplace=True)\n",
    "redteam_df.replace(\"?\",\"none\",inplace=True)\n",
    "redteam_df.to_csv(dst_redteam_path,index=False)\n",
    "\n",
    "red_team_first_event = redteam_df[\"time\"].min()\n",
    "print(red_team_first_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3704ed8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Time target: 237285\n"
     ]
    }
   ],
   "source": [
    "# Training Data Time target\n",
    "test_time_target = red_team_first_event+day_seconds\n",
    "print(f\"Testing Data Time target: {test_time_target}\")\n",
    "chunk_size = 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2265582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks Processed:  1\n",
      "Chunks Processed:  2\n",
      "Chunks Processed:  3\n",
      "Chunks Processed:  4\n",
      "Chunks Processed:  5\n",
      "Chunks Processed:  6\n",
      "Chunks Processed:  7\n",
      "Chunks Processed:  8\n",
      "Chunks Processed:  9\n",
      "Chunks Processed:  10\n",
      "Chunks Processed:  11\n",
      "Chunks Processed:  12\n",
      "Chunks Processed:  13\n",
      "Chunks Processed:  14\n",
      "Chunks Processed:  15\n",
      "Chunks Processed:  16\n",
      "Chunks Processed:  17\n"
     ]
    }
   ],
   "source": [
    "auth_headers = [\n",
    "    \"time\",\n",
    "    \"source_user@domain\",\n",
    "    \"destination_user@domain\",\n",
    "    \"src_comp\",\n",
    "    \"dst_comp\",\n",
    "    \"auth_type\",\n",
    "    \"logon_type\",\n",
    "    \"auth_orient\",\n",
    "    \"pass_fail\",\n",
    "]\n",
    "\n",
    "auth_df = pd.read_csv(src_auth_path, header=None, chunksize=chunk_size, names=auth_headers)\n",
    "chunk_count = 0\n",
    "header = True\n",
    "\n",
    "for chunk in auth_df:\n",
    "    # make sure time is int\n",
    "    chunk[\"time\"] = chunk[\"time\"].astype(int)\n",
    "    times = chunk[\"time\"]\n",
    "\n",
    "    if train:\n",
    "        # only keep pre–first red team\n",
    "        chunk = chunk[times < red_team_first_event]\n",
    "        if chunk.empty:\n",
    "            break\n",
    "    else:\n",
    "        # 1) If entire chunk is before the red-team start, skip it\n",
    "        if times.max() < red_team_first_event:\n",
    "            continue\n",
    "\n",
    "        # 2) If the entire chunk is beyond your test cutoff, STOP reading\n",
    "        if times.min() > test_time_target:\n",
    "            break\n",
    "\n",
    "        # 3) Now filter to the window you actually want to process\n",
    "        chunk = chunk[(times >= red_team_first_event) & \n",
    "                      (times <= test_time_target)]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "\n",
    "    # … process and write out chunk …\n",
    "    chunk[['src_user', 'src_domain']] = chunk[\"source_user@domain\"].str.split(\"@\", expand=True)\n",
    "    chunk[['dst_user', 'dst_domain']] = chunk[\"destination_user@domain\"].str.split(\"@\", expand=True)\n",
    "    chunk.drop(columns=[\"source_user@domain\", \"destination_user@domain\"], inplace=True)\n",
    "    chunk['event_type'] = 'auth'\n",
    "    chunk.replace(\"?\", \"none\", inplace=True)\n",
    "\n",
    "    chunk_count += 1\n",
    "    print(f\"Chunks Processed:  {chunk_count}\")\n",
    "\n",
    "    chunk.to_csv(dst_auth_path, mode='a', index=False, header=header)\n",
    "    header = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb8f7040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks Processed:  1\n"
     ]
    }
   ],
   "source": [
    "dns_headers = [\"time\",\n",
    "               \"src_compr\",\n",
    "               \"comp_rsvd\"]\n",
    "dns_df = pd.read_csv(src_dns_path, header=None,chunksize=chunk_size, names=dns_headers)\n",
    "chunk_count = 0\n",
    "\n",
    "header=True\n",
    "\n",
    "for chunk in dns_df:\n",
    "    # make sure time is int\n",
    "    chunk[\"time\"] = chunk[\"time\"].astype(int)\n",
    "    times = chunk[\"time\"]\n",
    "\n",
    "    if train:\n",
    "        # only keep pre–first red team\n",
    "        chunk = chunk[times < red_team_first_event]\n",
    "        if chunk.empty:\n",
    "            break\n",
    "    else:\n",
    "        # 1) If entire chunk is before the red-team start, skip it\n",
    "        if times.max() < red_team_first_event:\n",
    "            continue\n",
    "\n",
    "        # 2) If the entire chunk is beyond your test cutoff, STOP reading\n",
    "        if times.min() > test_time_target:\n",
    "            break\n",
    "\n",
    "        # 3) Now filter to the window you actually want to process\n",
    "        chunk = chunk[(times >= red_team_first_event) & \n",
    "                      (times <= test_time_target)]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "    chunk['event_type'] = 'dns'\n",
    "    chunk.replace(\"?\",\"none\", inplace=True)\n",
    "    chunk_count+=1\n",
    "    print(f\"Chunks Processed:  {chunk_count}\")\n",
    "    if header:\n",
    "        chunk.to_csv(dst_dns_path, mode='a', index=False, header=True)\n",
    "        header=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b453d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks Processed:  1\n",
      "Chunks Processed:  2\n",
      "Chunks Processed:  3\n",
      "Chunks Processed:  4\n",
      "Chunks Processed:  5\n",
      "Chunks Processed:  6\n",
      "Chunks Processed:  7\n",
      "Chunks Processed:  8\n",
      "Chunks Processed:  9\n",
      "Chunks Processed:  10\n"
     ]
    }
   ],
   "source": [
    "flows_headers = [\"time\",\n",
    "                 \"dur\",\n",
    "                 \"src_comp\",\n",
    "                 \"src_port\",\n",
    "                 \"dst_comp\",\n",
    "                 \"dst_port\",\n",
    "                 \"prtcl\",\n",
    "                 \"pckt_cnt\",\n",
    "                 \"byte_cnt\"]\n",
    "flows_df = pd.read_csv(src_flows_path, header=None,chunksize=chunk_size, names=flows_headers)\n",
    "chunk_count = 0\n",
    "\n",
    "header=True\n",
    "\n",
    "for chunk in flows_df:\n",
    "    # make sure time is int\n",
    "    chunk[\"time\"] = chunk[\"time\"].astype(int)\n",
    "    times = chunk[\"time\"]\n",
    "\n",
    "    if train:\n",
    "        # only keep pre–first red team\n",
    "        chunk = chunk[times < red_team_first_event]\n",
    "        if chunk.empty:\n",
    "            break\n",
    "    else:\n",
    "        # 1) If entire chunk is before the red-team start, skip it\n",
    "        if times.max() < red_team_first_event:\n",
    "            continue\n",
    "\n",
    "        # 2) If the entire chunk is beyond your test cutoff, STOP reading\n",
    "        if times.min() > test_time_target:\n",
    "            break\n",
    "\n",
    "        # 3) Now filter to the window you actually want to process\n",
    "        chunk = chunk[(times >= red_team_first_event) & \n",
    "                      (times <= test_time_target)]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "    chunk['event_type'] = 'flow'\n",
    "    chunk.replace(\"?\",\"none\", inplace=True)\n",
    "    chunk_count+=1\n",
    "    print(f\"Chunks Processed:  {chunk_count}\")\n",
    "    if header:\n",
    "        chunk.to_csv(dst_flows_path, mode='a', index=False, header=True)\n",
    "        header=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7d47437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks Processed:  1\n",
      "Chunks Processed:  2\n",
      "Chunks Processed:  3\n",
      "Chunks Processed:  4\n",
      "Chunks Processed:  5\n",
      "Chunks Processed:  6\n",
      "Chunks Processed:  7\n"
     ]
    }
   ],
   "source": [
    "proc_headers = [\"time\",\n",
    "                \"user@domain\",\n",
    "                \"src_comp\",\n",
    "                \"proc_name\",\n",
    "                \"start/end\"]\n",
    "proc_df = pd.read_csv(src_proc_path, header=None,chunksize=chunk_size, names=proc_headers)\n",
    "chunk_count = 0\n",
    "\n",
    "header=True\n",
    "\n",
    "for chunk in proc_df:\n",
    "    # make sure time is int\n",
    "    chunk[\"time\"] = chunk[\"time\"].astype(int)\n",
    "    times = chunk[\"time\"]\n",
    "\n",
    "    if train:\n",
    "        # only keep pre–first red team\n",
    "        chunk = chunk[times < red_team_first_event]\n",
    "        if chunk.empty:\n",
    "            break\n",
    "    else:\n",
    "        # 1) If entire chunk is before the red-team start, skip it\n",
    "        if times.max() < red_team_first_event:\n",
    "            continue\n",
    "\n",
    "        # 2) If the entire chunk is beyond your test cutoff, STOP reading\n",
    "        if times.min() > test_time_target:\n",
    "            break\n",
    "\n",
    "        # 3) Now filter to the window you actually want to process\n",
    "        chunk = chunk[(times >= red_team_first_event) & \n",
    "                      (times <= test_time_target)]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "    chunk[['src_user', 'src_domain']] = chunk[\"user@domain\"].str.split(\"@\", expand=True)\n",
    "    chunk.drop(columns=[\"user@domain\"], inplace=True)\n",
    "    chunk['event_type'] = 'proc'\n",
    "    chunk.replace(\"?\",\"none\", inplace=True)\n",
    "    chunk_count+=1\n",
    "    print(f\"Chunks Processed:  {chunk_count}\")\n",
    "    if header:\n",
    "        chunk.to_csv(dst_proc_path, mode='a', index=False, header=True)\n",
    "        header=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a445bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = pd.read_csv(dst_auth_path,header=0)\n",
    "dns = pd.read_csv(dst_dns_path,header=0)\n",
    "flows = pd.read_csv(dst_flows_path,header=0)\n",
    "procs = pd.read_csv(dst_proc_path,header=0)\n",
    "\n",
    "final_df = pd.concat([auth,dns,flows,procs],ignore_index=True)\n",
    "final_df[['dur', 'pckt_cnt', 'byte_cnt']] = final_df[['dur', 'pckt_cnt', 'byte_cnt']].fillna(0)\n",
    "final_df = final_df.fillna(\"none\").sort_values('time')\n",
    "if train:\n",
    "    final_df.to_csv(train_final_path,index=False)\n",
    "else:\n",
    "    final_df.to_csv(test_final_path,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
